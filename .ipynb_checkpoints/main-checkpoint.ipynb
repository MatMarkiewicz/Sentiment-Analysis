{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import re\n",
    "import string\n",
    "import cvxopt\n",
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.svm import SVC\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import scipy.optimize as sopt\n",
    "import scipy.stats as sstats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Macro for windows / mac users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#system = 'Mac'\n",
    "system = 'Win'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing data (IMDb movies' reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_path = 'data_sets/aclImdb/train/pos/*'\n",
    "train_neg_path = 'data_sets/aclImdb/train/neg/*'\n",
    "\n",
    "train_pos = glob.glob(train_pos_path)\n",
    "train_neg = glob.glob(train_neg_path)\n",
    "\n",
    "\n",
    "test_pos_path = 'data_sets/aclImdb/test/pos/*'\n",
    "test_neg_path = 'data_sets/aclImdb/test/neg/*'\n",
    "\n",
    "test_pos = glob.glob(test_pos_path)\n",
    "test_neg = glob.glob(test_neg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    }
   ],
   "source": [
    "train_df = []\n",
    "test_df = []\n",
    "\n",
    "for path in tqdm(train_pos, desc='Getting positive train data', position=0, leave=False):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "        \n",
    "#         For win users\n",
    "        if system == 'Win':\n",
    "            beg, end = path.find('\\\\'), path.find('.')\n",
    "        \n",
    "#         For mac users\n",
    "        if system == 'Mac':\n",
    "            beg = re.search(r\"\\d\",path).start()-1\n",
    "            end = path.find('.')\n",
    "            \n",
    "        idx, rating = path[beg+1:-4].split('_')\n",
    "        train_df.append([text, rating])\n",
    "        \n",
    "for path in tqdm(train_neg, desc='Getting negative train data', position=0, leave=False):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "        \n",
    "#         For win users\n",
    "        if system == 'Win':\n",
    "            beg, end = path.find('\\\\'), path.find('.')\n",
    "        \n",
    "#         For mac users\n",
    "        if system == 'Mac':\n",
    "            beg = re.search(r\"\\d\",path).start()-1\n",
    "            end = path.find('.')\n",
    "\n",
    "        idx, rating = path[beg+1:-4].split('_')\n",
    "        train_df.append([text, rating])\n",
    "         \n",
    "for path in tqdm(test_pos, desc='Getting positive test data', position=0, leave=False):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "        \n",
    "#         For win users\n",
    "        if system == 'Win':\n",
    "            beg, end = path.find('\\\\'), path.find('.')\n",
    "        \n",
    "#         For mac users\n",
    "        if system == 'Mac':\n",
    "            beg = re.search(r\"\\d\",path).start()-1\n",
    "            end = path.find('.')\n",
    "            \n",
    "        idx, rating = path[beg+1:-4].split('_')\n",
    "        test_df.append([text, rating])\n",
    "   \n",
    "for path in tqdm(test_neg, desc='Getting negative test data', position=0, leave=False):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "#         For win users\n",
    "        if system == 'Win':\n",
    "            beg, end = path.find('\\\\'), path.find('.')\n",
    "        \n",
    "#         For mac users\n",
    "        if system == 'Mac':\n",
    "            beg = re.search(r\"\\d\",path).start()-1\n",
    "            end = path.find('.')\n",
    "            \n",
    "        idx, rating = path[beg+1:-4].split('_')\n",
    "        test_df.append([text, rating])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_df, columns=['text', 'rating'])\n",
    "test_df = pd.DataFrame(test_df, columns=['text', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records:  50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text rating\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...      9\n",
       "1  Homelessness (or Houselessness as George Carli...      8\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...     10\n",
       "3  This is easily the most underrated film inn th...      7\n",
       "4  This is not the typical Mel Brooks film. It wa...      8"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Records: ', train_df.size)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews with rating 1: 5100\n",
      "Number of reviews with rating 2: 2284\n",
      "Number of reviews with rating 3: 2420\n",
      "Number of reviews with rating 4: 2696\n",
      "Number of reviews with rating 5: 0\n",
      "Number of reviews with rating 6: 0\n",
      "Number of reviews with rating 7: 2496\n",
      "Number of reviews with rating 8: 3009\n",
      "Number of reviews with rating 9: 2263\n",
      "Number of reviews with rating 10: 4732\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    print(f'Number of reviews with rating {i}: {train_df[train_df.rating == str(i)].shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Remove punctuaction and lower all texts\n",
    "train_df.text = train_df.text.apply(lambda row: regex(row))\n",
    "test_df.text = test_df.text.apply(lambda row: regex(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>bromwell high is a cartoon comedy it ran at th...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>homelessness or houselessness as george carlin...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>brilliant overacting by lesley ann warren best...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>this is easily the most underrated film inn th...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>this is not the typical mel brooks film it was...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text rating\n",
       "0  bromwell high is a cartoon comedy it ran at th...      9\n",
       "1  homelessness or houselessness as george carlin...      8\n",
       "2  brilliant overacting by lesley ann warren best...     10\n",
       "3  this is easily the most underrated film inn th...      7\n",
       "4  this is not the typical mel brooks film it was...      8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider only rating 1 and 10\n",
    "bayes_df_train = train_df[(train_df.rating == '1') | (train_df.rating == '10')]\n",
    "bayes_df_test = test_df[(test_df.rating == '1') | (test_df.rating == '10')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_(text):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_train_df = bayes_df_train.copy()\n",
    "stemmed_test_df = bayes_df_test.copy()\n",
    "stemmed_train_df.text = stemmed_train_df.text.apply(lambda row: stem_(row))\n",
    "stemmed_test_df.text = stemmed_test_df.text.apply(lambda row: stem_(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "swr_train_df = bayes_df_train.copy()\n",
    "swr_test_df = bayes_df_test.copy()\n",
    "swr_train_df.text = swr_train_df.text.apply(lambda row: remove_stop_words(row))\n",
    "swr_test_df.text = swr_test_df.text.apply(lambda row: remove_stop_words(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_and_remove_stop_words(text):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_swr_train_df = bayes_df_train.copy()\n",
    "stemmed_swr_test_df = bayes_df_test.copy()\n",
    "stemmed_swr_train_df.text = stemmed_swr_train_df.text.apply(lambda row: stem_and_remove_stop_words(row))\n",
    "stemmed_swr_test_df.text = stemmed_swr_test_df.text.apply(lambda row: stem_and_remove_stop_words(row))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_score(preds,Y,name):\n",
    "    print(name)\n",
    "    acc = np.mean(preds == Y)\n",
    "    print(f\"Acc: {acc}\")\n",
    "    M = metrics.confusion_matrix(preds,Y)\n",
    "    N = np.sum(M)\n",
    "    print('\\nConfusion matrix:')\n",
    "    print(M)\n",
    "    print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "    print(f'True positive (rating = 10): {M[1][1]}')\n",
    "    print(f'False negative: {M[0][1]}')\n",
    "    print(f'False positive: {M[1][0]}')\n",
    "    return M,N,acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCountVectorizer:\n",
    "    def __init__(self, min_df=-1, max_df=1e18, binary=False):\n",
    "        self.min_df = min_df\n",
    "        self.max_df = max_df\n",
    "        self.binary = binary\n",
    "    \n",
    "    def fit(self, df):\n",
    "        words_cnt = defaultdict(int)\n",
    "        col = df.columns[0]\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            text = df.iloc[i][col]\n",
    "            for word in text.split():\n",
    "                words_cnt[word] += 1\n",
    "                \n",
    "        all_words = []\n",
    "        for word, cnt in words_cnt.items():\n",
    "            if self.min_df <= cnt <= self.max_df:\n",
    "                all_words.append(word)\n",
    "                \n",
    "        self.all_words_ids = {w:i for i,w in enumerate(all_words)}\n",
    "        self.width = len(all_words)\n",
    "        \n",
    "    \n",
    "    def transform(self, df):\n",
    "        col = df.columns[0]\n",
    "        count_matrix = np.zeros([len(df), self.width], \\\n",
    "                                dtype=np.int32)\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            text = df.iloc[i][col]\n",
    "            words_cnt = defaultdict(int)\n",
    "            \n",
    "            for word in text.split():\n",
    "                words_cnt[word] += 1\n",
    "            \n",
    "            for word, cnt in words_cnt.items():\n",
    "                if word in self.all_words_ids:\n",
    "                    pos = self.all_words_ids[word]\n",
    "                    if self.binary:\n",
    "                        count_matrix[i][pos] = 1\n",
    "                    else:\n",
    "                        count_matrix[i][pos] = cnt\n",
    "                    \n",
    "        return count_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive_Bayes:\n",
    "    def __init__(self,alpha=0,fit_prior=True,class_prior=None):\n",
    "        self.alpha = alpha\n",
    "        self.fit_prior = fit_prior\n",
    "        self.class_prior_array = class_prior\n",
    "        if class_prior:\n",
    "            self.fit_prior = False\n",
    "    \n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.classes,prior = np.unique(y,return_counts=True)\n",
    "        self.N = len(y)\n",
    "        \n",
    "        # Setting class prior\n",
    "        if self.fit_prior:\n",
    "            self.class_prior = {class_ : np.log(prior[i]/self.N + 1e-100)\n",
    "                                for i,class_ in enumerate(self.classes)}\n",
    "        elif self.class_prior_array:\n",
    "            self.class_prior = {class_ : np.log(self.class_prior_array[i] + 1e-100) \n",
    "                                for i,class_ in enumerate(self.classes)}\n",
    "        else:\n",
    "            self.class_prior = {class_ : np.log(1/len(self.classes) + 1e-100) \n",
    "                                for class_ in self.classes}\n",
    "            \n",
    "        # Creating words dictionaries\n",
    "        self.class_words_counts = {class_ : defaultdict(lambda: 0) \n",
    "                                   for class_ in self.classes}\n",
    "        for i,text in enumerate(X):\n",
    "            target = y[i]\n",
    "            for word in text.split():\n",
    "                self.class_words_counts[target][word] += 1\n",
    "        \n",
    "        # Creating probabilities dictionaries\n",
    "        self.class_words_probs = {class_ : defaultdict(lambda: np.log(self.alpha + 1e-100)) \n",
    "                                  for class_ in self.classes}\n",
    "        for class_,dict_ in self.class_words_counts.items():\n",
    "            for word,count in dict_.items():\n",
    "                self.class_words_probs[class_][word] = np.log(count + 1e-100)\n",
    "    \n",
    "        self.class_words_amount = {class_ : np.log(sum(self.class_words_counts[class_].values())) \n",
    "                                   for class_ in self.classes}\n",
    "    \n",
    "\n",
    "    def get_class_log_probabilities(self,text):\n",
    "        probs = {class_ : 0 for class_ in self.classes}\n",
    "        for class_ in self.classes:\n",
    "            for word in text.split():\n",
    "                probs[class_] += self.class_words_probs[class_][word]\n",
    "                probs[class_] -= self.class_words_amount[class_]\n",
    "            probs[class_] += self.class_prior[class_]\n",
    "        return probs\n",
    "    \n",
    "    \n",
    "    def predict(self,X,return_probabilities = False):\n",
    "        preds = []\n",
    "        preds_probs = []\n",
    "        for text in X:\n",
    "            prob = self.get_class_log_probabilities(text)\n",
    "            #prob = {class_ : np.exp(pbb) for class_,pbb in prob.items()}\n",
    "            preds_probs.append(prob)\n",
    "            pred = max(prob,key = prob.get)\n",
    "            preds.append(pred)\n",
    "        \n",
    "        if return_probabilities:\n",
    "            return preds,preds_probs\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = np.array(bayes_df_train['text']),np.array(bayes_df_train['rating'])\n",
    "X_test,y_test = np.array(bayes_df_test['text']),np.array(bayes_df_test['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBc_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.5\n",
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,ppb = NB.predict(X_train,return_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN, alpha : 1.5\n",
      "Acc: 0.9363303498779495\n",
      "\n",
      "Confusion matrix:\n",
      "[[4904  430]\n",
      " [ 196 4302]]\n",
      "\n",
      "True negative (rating = 1): 4904\n",
      "True positive (rating = 10): 4302\n",
      "False negative: 430\n",
      "False positive: 196\n"
     ]
    }
   ],
   "source": [
    "M,N,acc = print_score(predictions,y_train,f\"TRAIN, alpha : {alpha}\")\n",
    "NBc_res.append(['Org train data\\na=1.5','Acc',acc])\n",
    "NBc_res.append(['Org train data\\na=1.5','FN',M[0][1]/N])\n",
    "NBc_res.append(['Org train data\\na=1.5','FP',M[1][0]/N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,ppb = NB.predict(X_test,return_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.5\n",
      "Acc: 0.8893324019558926\n",
      "\n",
      "Confusion matrix:\n",
      "[[4651  738]\n",
      " [ 371 4261]]\n",
      "\n",
      "True negative (rating = 1): 4651\n",
      "True positive (rating = 10): 4261\n",
      "False negative: 738\n",
      "False positive: 371\n"
     ]
    }
   ],
   "source": [
    "M,N,acc = print_score(predictions,y_test,f\"TEST, alpha : {alpha}\")\n",
    "NBc_res.append(['Org test data\\na=1.5','Acc',acc])\n",
    "NBc_res.append(['Org test data\\na=1.5','FN',M[0][1]/N])\n",
    "NBc_res.append(['Org test data\\na=1.5','FP',M[1][0]/N])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try use alpha = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0\n",
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,ppb = NB.predict(X_train,return_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN, alpha : 0.0\n",
      "Acc: 0.9899308380797396\n",
      "\n",
      "Confusion matrix:\n",
      "[[5092   91]\n",
      " [   8 4641]]\n",
      "\n",
      "True negative (rating = 1): 5092\n",
      "True positive (rating = 10): 4641\n",
      "False negative: 91\n",
      "False positive: 8\n"
     ]
    }
   ],
   "source": [
    "M,N,acc = print_score(predictions,y_train,f\"TRAIN, alpha : {alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,ppb = NB.predict(X_test,return_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 0.0\n",
      "Acc: 0.7240794331903003\n",
      "\n",
      "Confusion matrix:\n",
      "[[3932 1675]\n",
      " [1090 3324]]\n",
      "\n",
      "True negative (rating = 1): 3932\n",
      "True positive (rating = 10): 3324\n",
      "False negative: 1675\n",
      "False positive: 1090\n"
     ]
    }
   ],
   "source": [
    "M,N,acc = print_score(predictions,y_test,f\"TEST, alpha : {alpha}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting alpha to 0 improve our train accuracy, but decrease train accuracy, so it`s overfitting. \n",
    "We can try to find best alpha for our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha : 0.0, test acc: 0.7240794331903003\n",
      "Alpha : 0.25, test acc: 0.8820476998303562\n",
      "Alpha : 0.5, test acc: 0.8868376409539966\n",
      "Alpha : 0.75, test acc: 0.8882347071150584\n",
      "Alpha : 1.0, test acc: 0.8884342879952101\n",
      "Alpha : 1.25, test acc: 0.8881349166749826\n",
      "Alpha : 1.5, test acc: 0.8893324019558926\n",
      "Alpha : 1.75, test acc: 0.8884342879952101\n",
      "Alpha : 2.0, test acc: 0.8882347071150584\n",
      "Alpha : 3.0, test acc: 0.8872368027142999\n",
      "Alpha : 4.0, test acc: 0.8862388983135415\n",
      "Alpha : 5.0, test acc: 0.8830456042311147\n",
      "Alpha : 10.0, test acc: 0.8759604829857299\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.0,0.25,0.5,0.75,1.0,1.25,1.5,1.75,2.0,3.0,4.0,5.0,10.0]:\n",
    "    NB = Naive_Bayes(fit_prior = False,alpha=alpha)\n",
    "    NB.fit(X_train,y_train)\n",
    "    predictions,ppb = NB.predict(X_test,return_probabilities=True)\n",
    "    acc = np.mean(predictions == y_test)\n",
    "    print(f'Alpha : {alpha}, test acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and stop words removing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.5, stemmed\n",
      "Acc: 0.8827462329108872\n",
      "\n",
      "Confusion matrix:\n",
      "[[4623  776]\n",
      " [ 399 4223]]\n",
      "\n",
      "True negative (rating = 1): 4623\n",
      "True positive (rating = 10): 4223\n",
      "False negative: 776\n",
      "False positive: 399\n"
     ]
    }
   ],
   "source": [
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)\n",
    "NB.fit(np.array(stemmed_train_df['text']),np.array(stemmed_train_df['rating']))\n",
    "predictions = NB.predict(np.array(stemmed_test_df['text']))\n",
    "M,N,acc = print_score(predictions,np.array(stemmed_test_df['rating']),\n",
    "                      f\"TEST, alpha : {alpha}, stemmed\")\n",
    "NBc_res.append(['Stemmed test data\\na=1.5','Acc',acc])\n",
    "NBc_res.append(['Stemmed test data\\na=1.5','FN',M[0][1]/N])\n",
    "NBc_res.append(['Stemmed test data\\na=1.5','FP',M[1][0]/N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.5, stop words removed\n",
      "Acc: 0.8995110268436284\n",
      "\n",
      "Confusion matrix:\n",
      "[[4656  641]\n",
      " [ 366 4358]]\n",
      "\n",
      "True negative (rating = 1): 4656\n",
      "True positive (rating = 10): 4358\n",
      "False negative: 641\n",
      "False positive: 366\n"
     ]
    }
   ],
   "source": [
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)\n",
    "NB.fit(np.array(swr_train_df['text']),np.array(swr_test_df['rating']))\n",
    "predictions = NB.predict(np.array(swr_test_df['text']))\n",
    "M,N,acc = print_score(predictions,np.array(stemmed_test_df['rating']),\n",
    "                      f\"TEST, alpha : {alpha}, stop words removed\")\n",
    "NBc_res.append(['Test data\\nwithout stopwords\\na=1.5','Acc',acc])\n",
    "NBc_res.append(['Test data\\nwithout stopwords\\na=1.5','FN',M[0][1]/N])\n",
    "NBc_res.append(['Test data\\nwithout stopwords\\na=1.5','FP',M[1][0]/N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.5, stemmed and stop words removed\n",
      "Acc: 0.8827462329108872\n",
      "\n",
      "Confusion matrix:\n",
      "[[4623  776]\n",
      " [ 399 4223]]\n",
      "\n",
      "True negative (rating = 1): 4623\n",
      "True positive (rating = 10): 4223\n",
      "False negative: 776\n",
      "False positive: 399\n"
     ]
    }
   ],
   "source": [
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)\n",
    "NB.fit(np.array(stemmed_swr_train_df['text']),np.array(stemmed_swr_train_df['rating']))\n",
    "predictions = NB.predict(np.array(stemmed_swr_test_df['text']))\n",
    "M,N,acc = print_score(predictions,np.array(stemmed_test_df['rating']),\n",
    "                      f\"TEST, alpha : {alpha}, stemmed and stop words removed\")\n",
    "NBc_res.append(['Stemmed test data\\nwithout stop words\\na=1.5','Acc',acc])\n",
    "NBc_res.append(['Stemmed test data\\nwithout stop words\\na=1.5','FN',M[0][1]/N])\n",
    "NBc_res.append(['Stemmed test data\\nwithout stop words\\na=1.5','FP',M[1][0]/N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBc_res_df = pd.DataFrame(NBc_res,columns = ['Data','Y','Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, 'Our Naive Bayes class')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 773.875x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x=\"Data\", y=\"Value\", hue=\"Y\", data=NBc_res_df,\n",
    "                height=5, aspect = 2, kind=\"bar\", palette=\"muted\")\n",
    "plt.title(\"Our Naive Bayes class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Sklearn Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBb_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_NB = CountVectorizer()\n",
    "X_train,y_train = np.array(bayes_df_train['text']),np.array(bayes_df_train['rating'])\n",
    "X_test,y_test = np.array(bayes_df_test['text']),np.array(bayes_df_test['rating'])\n",
    "X_train_cv = CV_NB.fit_transform(X_train)\n",
    "X_test_cv = CV_NB.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN, alpha : 1.5\n",
      "Acc: 0.9509764035801465\n",
      "\n",
      "Confusion matrix:\n",
      "[[5009  391]\n",
      " [  91 4341]]\n",
      "\n",
      "True negative (rating = 1): 5009\n",
      "True positive (rating = 10): 4341\n",
      "False negative: 391\n",
      "False positive: 91\n"
     ]
    }
   ],
   "source": [
    "alpha = 1.5\n",
    "MNB = MultinomialNB(alpha = 1.5)\n",
    "MNB.fit(X_train_cv,y_train)\n",
    "predictions = MNB.predict(X_train_cv)\n",
    "M,N,acc = print_score(predictions,y_train,f\"TRAIN, alpha : {alpha}\")\n",
    "NBb_res.append(['Org train data\\na=1.5','Acc',acc])\n",
    "NBb_res.append(['Org train data\\na=1.5','FN',M[0][1]/N])\n",
    "NBb_res.append(['Org train data\\na=1.5','FP',M[1][0]/N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.5\n",
      "Acc: 0.884742041712404\n",
      "\n",
      "Confusion matrix:\n",
      "[[4738  871]\n",
      " [ 284 4128]]\n",
      "\n",
      "True negative (rating = 1): 4738\n",
      "True positive (rating = 10): 4128\n",
      "False negative: 871\n",
      "False positive: 284\n"
     ]
    }
   ],
   "source": [
    "alpha = 1.5\n",
    "MNB = MultinomialNB(alpha = 1.5)\n",
    "MNB.fit(X_train_cv,y_train)\n",
    "predictions = MNB.predict(X_test_cv)\n",
    "M,N,acc = print_score(predictions,y_test,f\"TEST, alpha : {alpha}\")\n",
    "NBb_res.append(['Org test data\\na=1.5','Acc',acc])\n",
    "NBb_res.append(['Org test data\\na=1.5','FN',M[0][1]/N])\n",
    "NBb_res.append(['Org test data\\na=1.5','FP',M[1][0]/N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_NB = CountVectorizer()\n",
    "X_train,y_train = np.array(stemmed_train_df['text']),np.array(stemmed_train_df['rating'])\n",
    "X_test,y_test = np.array(stemmed_test_df['text']),np.array(stemmed_test_df['rating'])\n",
    "X_train_cv = CV_NB.fit_transform(X_train)\n",
    "X_test_cv = CV_NB.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.5, stemmed\n",
      "Acc: 0.8805508432292186\n",
      "\n",
      "Confusion matrix:\n",
      "[[4710  885]\n",
      " [ 312 4114]]\n",
      "\n",
      "True negative (rating = 1): 4710\n",
      "True positive (rating = 10): 4114\n",
      "False negative: 885\n",
      "False positive: 312\n"
     ]
    }
   ],
   "source": [
    "alpha = 1.5\n",
    "MNB = MultinomialNB(alpha = 1.5)\n",
    "MNB.fit(X_train_cv,y_train)\n",
    "predictions = MNB.predict(X_test_cv)\n",
    "M,N,acc = print_score(predictions,y_test,\n",
    "                      f\"TEST, alpha : {alpha}, stemmed\")\n",
    "NBb_res.append(['Stemmed test data\\na=1.5','Acc',acc])\n",
    "NBb_res.append(['Stemmed test data\\na=1.5','FN',M[0][1]/N])\n",
    "NBb_res.append(['Stemmed test data\\na=1.5','FP',M[1][0]/N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_NB = CountVectorizer()\n",
    "X_train,y_train = np.array(swr_train_df['text']),np.array(swr_train_df['rating'])\n",
    "X_test,y_test = np.array(swr_test_df['text']),np.array(swr_test_df['rating'])\n",
    "X_train_cv = CV_NB.fit_transform(X_train)\n",
    "X_test_cv = CV_NB.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.5, stemmed\n",
      "Acc: 0.8932242291188505\n",
      "\n",
      "Confusion matrix:\n",
      "[[4752  800]\n",
      " [ 270 4199]]\n",
      "\n",
      "True negative (rating = 1): 4752\n",
      "True positive (rating = 10): 4199\n",
      "False negative: 800\n",
      "False positive: 270\n"
     ]
    }
   ],
   "source": [
    "alpha = 1.5\n",
    "MNB = MultinomialNB(alpha = 1.5)\n",
    "MNB.fit(X_train_cv,y_train)\n",
    "predictions = MNB.predict(X_test_cv)\n",
    "M,N,acc = print_score(predictions,y_test,\n",
    "                      f\"TEST, alpha : {alpha}, stemmed\")\n",
    "NBb_res.append(['Test data\\nwithout stopwords\\na=1.5','Acc',acc])\n",
    "NBb_res.append(['Test data\\nwithout stopwords\\na=1.5','FN',M[0][1]/N])\n",
    "NBb_res.append(['Test data\\nwithout stopwords\\na=1.5','FP',M[1][0]/N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_NB = CountVectorizer()\n",
    "X_train,y_train = np.array(stemmed_swr_train_df['text']),np.array(stemmed_swr_train_df['rating'])\n",
    "X_test,y_test = np.array(stemmed_swr_test_df['text']),np.array(stemmed_swr_test_df['rating'])\n",
    "X_train_cv = CV_NB.fit_transform(X_train)\n",
    "X_test_cv = CV_NB.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.5, stemmed\n",
      "Acc: 0.8805508432292186\n",
      "\n",
      "Confusion matrix:\n",
      "[[4710  885]\n",
      " [ 312 4114]]\n",
      "\n",
      "True negative (rating = 1): 4710\n",
      "True positive (rating = 10): 4114\n",
      "False negative: 885\n",
      "False positive: 312\n"
     ]
    }
   ],
   "source": [
    "alpha = 1.5\n",
    "MNB = MultinomialNB(alpha = 1.5)\n",
    "MNB.fit(X_train_cv,y_train)\n",
    "predictions = MNB.predict(X_test_cv)\n",
    "M,N,acc = print_score(predictions,y_test,\n",
    "                      f\"TEST, alpha : {alpha}, stemmed\")\n",
    "NBb_res.append(['Stemmed test data\\nwithout stop words\\na=1.5','Acc',acc])\n",
    "NBb_res.append(['Stemmed test data\\nwithout stop words\\na=1.5','FN',M[0][1]/N])\n",
    "NBb_res.append(['Stemmed test data\\nwithout stop words\\na=1.5','FP',M[1][0]/N])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBb_res_df = pd.DataFrame(NBb_res,columns = ['Data','Y','Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, 'Sklearn MultinomialNaiveBayes')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 773.875x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x=\"Data\", y=\"Value\", hue=\"Y\", data=NBb_res_df,\n",
    "                height=5, aspect = 2, kind=\"bar\", palette=\"muted\")\n",
    "plt.title(\"Sklearn MultinomialNaiveBayes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5208: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "NBc_res_df_copyed = NBc_res_df.copy()\n",
    "A_df = NBc_res_df[NBc_res_df.Y == 'Acc']\n",
    "A_df.Y = ['Our'] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "NBb_res_df_copyed = NBb_res_df.copy()\n",
    "B_df = NBb_res_df[NBb_res_df.Y == 'Acc']\n",
    "B_df.Y = ['Sklearn'] * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_df = pd.concat([A_df,B_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, 'Our Naive Bayes class vs Sklearn MultinomialNaiveBayes')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 793.625x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x=\"Data\", y=\"Value\", hue=\"Y\", data=compare_df,\n",
    "                height=5, aspect = 2, kind=\"bar\", palette=\"muted\")\n",
    "plt.title(\"Our Naive Bayes class vs Sklearn MultinomialNaiveBayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self,C,gamma,th=1e-5):\n",
    "        self.C = C\n",
    "        self.gamma = gamma\n",
    "        self.th = th\n",
    "    def fit(self,X,y,info=False):\n",
    "        m,n = X.shape\n",
    "        \n",
    "        # kernel matrix\n",
    "        if info:\n",
    "            print(f'Calculating kernel matrix...',end='')\n",
    "        K = rbf_kernel(X,X,gamma=self.gamma)\n",
    "        \n",
    "        # setup solver\n",
    "        if info:\n",
    "            print(f'Setting solver...',end='')\n",
    "        P = cvxopt.matrix(np.outer(y,y) * K)\n",
    "        q = cvxopt.matrix(-np.ones((m, 1)))\n",
    "        G = cvxopt.matrix(np.vstack((np.eye(m)*-1,np.eye(m))))\n",
    "        h = cvxopt.matrix(np.hstack((np.zeros(m), np.ones(m) * self.C)))\n",
    "        A = cvxopt.matrix(y.reshape(1, -1))\n",
    "        b = cvxopt.matrix(np.zeros(1))\n",
    "        if info:\n",
    "            print(f'starting solver...')\n",
    "        sol = cvxopt.solvers.qp(P, q, G, h, A, b)\n",
    "        self.alphas = np.array(sol['x'])\n",
    "        \n",
    "        # getting support vectors\n",
    "        self.S = (self.alphas > self.th).reshape(-1, )\n",
    "        self.support_vextors = X[self.S]\n",
    "        self.sv_target = y[self.S]\n",
    "        \n",
    "        # getting bias\n",
    "        if info:\n",
    "            print(f'Calculating bias...',end='')\n",
    "        K_sv = rbf_kernel(self.support_vextors,self.support_vextors,gamma=self.gamma)\n",
    "        B = self.sv_target.ravel() - np.sum(K_sv * self.sv_target.ravel() * self.alphas[self.S].ravel(),axis=1)\n",
    "        self.bias = sstats.mode(B)[0][0]\n",
    "        \n",
    "        if info:\n",
    "            print(f'done')\n",
    "        \n",
    "    def predict(self,X):\n",
    "        K = rbf_kernel(X,self.support_vextors,gamma=self.gamma)\n",
    "        preds = np.sign(np.sum(K * self.sv_target.ravel() * self.alphas[self.S].ravel(),axis=1) + self.bias)\n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = MyCountVectorizer(min_df = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV.fit(stemmed_swr_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_SVM,X_test_SVM = CV.transform(stemmed_swr_train_df),CV.transform(stemmed_swr_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([-1.0 if r == '1' else 1.0 for r in stemmed_swr_train_df['rating']]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([-1.0 if r == '1' else 1.0 for r in stemmed_swr_test_df['rating']]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVM(1,0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating kernel matrix...Setting solver...starting solver...\n",
      "     pcost       dcost       gap    pres   dres\n",
      " 0: -3.7223e+03 -2.3382e+04  8e+04  2e+00  1e-14\n",
      " 1: -3.5168e+03 -1.5382e+04  1e+04  5e-02  1e-14\n",
      " 2: -3.7530e+03 -5.6049e+03  2e+03  7e-03  1e-14\n",
      " 3: -4.0166e+03 -4.3279e+03  3e+02  6e-04  1e-14\n",
      " 4: -4.0819e+03 -4.1240e+03  4e+01  4e-05  1e-14\n",
      " 5: -4.0932e+03 -4.0968e+03  4e+00  6e-12  1e-14\n",
      " 6: -4.0944e+03 -4.0946e+03  2e-01  7e-12  1e-14\n",
      " 7: -4.0945e+03 -4.0945e+03  6e-03  4e-12  1e-14\n",
      " 8: -4.0945e+03 -4.0945e+03  3e-04  6e-12  1e-14\n",
      "Optimal solution found.\n",
      "Calculating bias...done\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(X_train_SVM,y_train,info=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions = svm_model.predict(X_test_SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, rbf kernel, C=1, gamma=0.04\n",
      "Acc: 0.85340784352859\n",
      "\n",
      "Confusion matrix:\n",
      "[[4187  634]\n",
      " [ 835 4365]]\n",
      "\n",
      "True negative (rating = 1): 4187\n",
      "True positive (rating = 10): 4365\n",
      "False negative: 634\n",
      "False positive: 835\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[4187,  634],\n",
       "        [ 835, 4365]], dtype=int64), 10021, 0.85340784352859)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_score(svm_predictions,y_test.ravel(),'SVM, rbf kernel, C=1, gamma=0.04')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sklearn built in Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Data vectorization (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_train_clean = np.array(train_df.text)\n",
    "reviews_test_clean = np.array(test_df.text)\n",
    "cv = CountVectorizer(binary=True)\n",
    "cv.fit(reviews_train_clean)\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.86576\n",
      "Accuracy for C=0.05: 0.87856\n",
      "Accuracy for C=0.25: 0.8784\n",
      "Accuracy for C=0.5: 0.87648\n",
      "Accuracy for C=1: 0.87504\n"
     ]
    }
   ],
   "source": [
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1]:    \n",
    "    lr = LogisticRegression(C=c,max_iter=300) # pobawic sie parametrami znalezc najlepsze\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "Removing stop words, stemming, encode review as a vector of words occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using reviews with rating equal 1 or 10 from training set. \n",
    "# Test samples rating will be also classified as 1 or 10\n",
    "LR_train_df = train_df[(train_df.rating == '1') | (train_df.rating == '10')]\n",
    "LR_test_df = test_df[(test_df.rating == '1') | (test_df.rating == '10')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_train_target = np.array([int(r) for r in LR_train_df['rating']]) // 10\n",
    "LR_test_target = np.array([int(r) for r in LR_test_df['rating']]) // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9832, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "stopwords_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sample):\n",
    "    words = sample.split()\n",
    "    words = [ stemmer.stem(word) for word in words if word not in stopwords_set ]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from train set\n",
    "sample = '''brilliant overacting by lesley ann warren best dramatic hobo lady i \n",
    "have ever seen and love scenes in clothes warehouse are second to none the corn \n",
    "on face is a classic as good as anything in blazing saddles the take on lawyers \n",
    "is also superb after being accused of being a turncoat selling out his boss and \n",
    "being dishonest the lawyer of pepto bolt shrugs indifferently im a lawyer he says \n",
    "three funny words jeffrey tambor a favorite from the later larry sanders show is \n",
    "fantastic here too as a mad millionaire who wants to crush the ghetto his character \n",
    "is more malevolent than usual the hospital scene and the scene where the homeless \n",
    "invade a demolition site are alltime classics look for the legs scene and the two \n",
    "big diggers fighting one bleeds this movie gets better each time i see it which is \n",
    "quite often'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brilliant overact lesley ann warren best dramat hobo ladi ever seen love scene cloth warehous second none corn face classic good anyth blaze saddl take lawyer also superb accus turncoat sell boss dishonest lawyer pepto bolt shrug indiffer im lawyer say three funni word jeffrey tambor favorit later larri sander show fantast mad millionair want crush ghetto charact malevol usual hospit scene scene homeless invad demolit site alltim classic look leg scene two big digger fight one bleed movi get better time see quit often'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(preprocess(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in LR_train_df.index:\n",
    "    sample = LR_train_df.loc[i]['text']\n",
    "    #words |= set(preprocess(sample)) <- for set of words\n",
    "    for word in preprocess(sample):\n",
    "        words[word] = words.get(word,0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17385"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from all stemmed words we consider only those, which occurs more than k times\n",
    "min_occur = 3\n",
    "all_train_words = list(filter(lambda w: words[w] >= min_occur,words))\n",
    "n_w = len(all_train_words)\n",
    "n_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_words_indexes = {w:i for i,w in enumerate(all_train_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(df):\n",
    "    data = []\n",
    "    for i in df.index:\n",
    "        v = np.zeros(n_w+1, dtype=np.int32)\n",
    "        v[0] = 1\n",
    "        sample = df.loc[i]['text']\n",
    "        words = preprocess(sample)\n",
    "        for word in words:\n",
    "            idx = all_train_words_indexes.get(word,-1)\n",
    "            if idx >= 0:\n",
    "                v[idx+1] += 1\n",
    "        data.append(v)\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_train = vectorize(LR_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9832, 17386)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Logistic Regression Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sopt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fb458e2c1cf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mLogistic_Regression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolver_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver_calls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-fb458e2c1cf5>\u001b[0m in \u001b[0;36mLogistic_Regression\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLogistic_Regression\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolver_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mTheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfmin_l_bfgs_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTheta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTheta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver_calls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolver_calls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sopt' is not defined"
     ]
    }
   ],
   "source": [
    "class Logistic_Regression:\n",
    "    def __init__(self,max_iter = 500,solver_calls = 5,Theta = None,solver = sopt.fmin_l_bfgs_b):\n",
    "        self.Theta = Theta\n",
    "        self.solver_calls = solver_calls\n",
    "        self.max_iter = max_iter\n",
    "        self.solver = solver\n",
    "    \n",
    "    def __sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))    \n",
    "    \n",
    "    def __logreg_loss(self,Theta, X, Y):\n",
    "        print(f\"Loss calculating... \",end=\"\")\n",
    "        Z = np.dot(Theta,X.T)\n",
    "        print(f\" Z done... \",end=\"\")\n",
    "        SZ = self.__sigmoid(Z)\n",
    "        nll = -np.sum([\n",
    "                        y * np.log2(SZ + 1e-7) \\\n",
    "                        + (1-y) * np.log2(1 - SZ + 1e-7) \\\n",
    "                        for y in Y\n",
    "                        ])\n",
    "        print(f\" nll done... \",end=\"\")\n",
    "        grad = np.dot(X.T, (SZ - Y).T )\n",
    "        print(f\" grad done... done \")\n",
    "        return nll, grad.reshape(Theta.shape)\n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        Theta = self.Theta\n",
    "        if Theta is None:\n",
    "            Theta = np.ones(X.shape[1])\n",
    "        for i in range(self.solver_calls):\n",
    "            Theta = self.solver(lambda th: self.__logreg_loss(th, X, y), Theta, maxiter=self.max_iter)[0]\n",
    "        self.Theta = Theta\n",
    "    \n",
    "    def __logreg_classify(self,x):\n",
    "        return (self.Theta.T.dot(x) >= 0)\n",
    "\n",
    "    def predict(self,Xs):\n",
    "        return [logreg_classify(self.Theta,x) for x in Xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorized_test = vectorize(LR_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8216744835844726\n"
     ]
    }
   ],
   "source": [
    "#print(\"Accuracy: %s\"  % accuracy_score(LR_test_target, logreg_predict(ThetaOpt,vectorized_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOD_WORDS = defaultdict(int)\n",
    "BAD_WORDS = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Bayes dictionaries: 9832it [00:02, 4182.13it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(bayes_df_train.iterrows(), desc='Creating Bayes dictionaries', position=0):\n",
    "    text, rating = row['text'], row['rating']\n",
    "    \n",
    "    for word in text.split():\n",
    "        if rating == '10':\n",
    "            GOOD_WORDS[word] += 1\n",
    "        else:\n",
    "            BAD_WORDS[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 56972),\n",
       " ('and', 30301),\n",
       " ('a', 26016),\n",
       " ('of', 25791),\n",
       " ('to', 22249),\n",
       " ('is', 19380),\n",
       " ('in', 16257),\n",
       " ('i', 14729),\n",
       " ('it', 14595),\n",
       " ('this', 13341)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent GOOD words\n",
    "list(sorted(GOOD_WORDS.items(), key=lambda x: x[1], reverse=True))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 58427),\n",
       " ('a', 28386),\n",
       " ('and', 26617),\n",
       " ('to', 26292),\n",
       " ('of', 25218),\n",
       " ('is', 18370),\n",
       " ('this', 18239),\n",
       " ('i', 17985),\n",
       " ('it', 15645),\n",
       " ('in', 15538)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent BAD words\n",
    "list(sorted(BAD_WORDS.items(), key=lambda x: x[1], reverse=True))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text, target_dict):\n",
    "    text = regex(text)\n",
    "    \n",
    "    for word in text.split():\n",
    "        if not word in target_dict:\n",
    "            target_dict[word] = 1\n",
    "            \n",
    "    sum_of_all = sum(target_dict.values())\n",
    "    \n",
    "    ppd = 0\n",
    "    for word in text.split():\n",
    "        ppd += np.log2(float(target_dict[word]) / sum_of_all)\n",
    "        \n",
    "    return ppd\n",
    "    \n",
    "    \n",
    "def predict(text):\n",
    "    ppd_good = classify(text, GOOD_WORDS)\n",
    "    ppd_bad = classify(text, BAD_WORDS)\n",
    "    \n",
    "    all_ppd = np.array([ppd_good, ppd_bad])\n",
    "    target = ['10', '1'][np.argmax(all_ppd)]\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Checking train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking train accuracy: 9832it [00:25, 378.44it/s]\n"
     ]
    }
   ],
   "source": [
    "correct, wrong = 0, 0\n",
    "real_targets, predictions = [], []\n",
    "\n",
    "for index, row in tqdm(bayes_df_train.iterrows(), desc='Checking train accuracy', position=0):\n",
    "    text, rating = row['text'], row['rating']\n",
    "    \n",
    "    pred = predict(text)\n",
    "    real_targets.append(rating)\n",
    "    predictions.append(pred)\n",
    "    if pred == rating:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 9346, Wrong: 486\n",
      "Accuracy: 95.05695687550855%\n",
      "\n",
      "Confusion matrix:\n",
      "[[4922  308]\n",
      " [ 178 4424]]\n",
      "\n",
      "True negative (rating = 1): 4922\n",
      "True positive (rating = 10): 4424\n",
      "False negative: 308\n",
      "False positive: 178\n"
     ]
    }
   ],
   "source": [
    "print(f'Correct: {correct}, Wrong: {wrong}')\n",
    "print(f'Accuracy: {correct / (wrong + correct) * 100}%')\n",
    "\n",
    "M = metrics.confusion_matrix(predictions, real_targets)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*So we are rather sceptic and most of our mistakes are movies which are good, but we classify them as bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Checking test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking test accuracy: 10021it [00:33, 297.44it/s]\n"
     ]
    }
   ],
   "source": [
    "correct, wrong = 0, 0\n",
    "real_targets, predictions = [], []\n",
    "\n",
    "for index, row in tqdm(bayes_df_test.iterrows(), desc='Checking test accuracy', position=0):\n",
    "    text, rating = row['text'], row['rating']\n",
    "    \n",
    "    pred = predict(text)\n",
    "    real_targets.append(rating)\n",
    "    predictions.append(pred)\n",
    "\n",
    "    if pred == rating:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 8901, Wrong: 1120\n",
      "Accuracy: 88.82347071150583%\n",
      "\n",
      "Confusion matrix:\n",
      "[[4689  787]\n",
      " [ 333 4212]]\n",
      "\n",
      "True negative (rating = 1): 4689\n",
      "True positive (rating = 10): 4212\n",
      "False negative: 787\n",
      "False positive: 333\n"
     ]
    }
   ],
   "source": [
    "print(f'Correct: {correct}, Wrong: {wrong}')\n",
    "print(f'Accuracy: {correct / (wrong + correct) * 100}%')\n",
    "\n",
    "M = metrics.confusion_matrix(predictions, real_targets)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Again we are sceptic"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "279.273px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
