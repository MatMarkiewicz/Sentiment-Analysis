{"cells":[{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":"# set up\nimport numpy as np\nimport pandas as pd\nimport glob\nimport re\nimport string \nfrom collections import defaultdict\nfrom sklearn import metrics\nfrom tqdm import tqdm\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport scipy.optimize as sopt"},{"cell_type":"markdown","metadata":{},"source":"# 1. Preparing data (IMDb movies' reviews)"},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":"train_pos_path = 'data_sets/movies/train/pos/*'\ntrain_neg_path = 'data_sets/movies/train/neg/*'\n\ntrain_pos = glob.glob(train_pos_path)\ntrain_neg = glob.glob(train_neg_path)\n\n\ntest_pos_path = 'data_sets/movies/test/pos/*'\ntest_neg_path = 'data_sets/movies/test/neg/*'\n\ntest_pos = glob.glob(test_pos_path)\ntest_neg = glob.glob(test_neg_path)"},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":"['data_sets/movies/train/pos/2239_7.txt',\n 'data_sets/movies/train/pos/3291_8.txt',\n 'data_sets/movies/train/pos/11920_9.txt']"},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":"train_pos[:3]"},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":"train_df = []\ntest_df = []"},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":"Getting positive train data: 100%|██████████| 12500/12500 [00:03<00:00, 3971.50it/s]\nGetting negative train data: 100%|██████████| 12500/12500 [00:02<00:00, 4195.53it/s]\nGetting positive test data: 100%|██████████| 12500/12500 [00:03<00:00, 3903.77it/s]\nGetting negative test data: 100%|██████████| 12500/12500 [00:03<00:00, 3969.23it/s]\n"}],"source":"for path in tqdm(train_pos, desc='Getting positive train data', position=0):\n    with open(path, encoding=\"utf8\") as f:\n        text = f.read()\n        # na windowsie to -> beg = path.find('\\\\') \n        beg = re.search(r\"\\d\",path).start()-1\n        end = path.find('.')\n        idx, rating = path[beg+1:end].split('_')\n        train_df.append([text, rating])\n        \n        \n\nfor path in tqdm(train_neg, desc='Getting negative train data', position=0):\n    with open(path, encoding=\"utf8\") as f:\n        text = f.read()\n        # beg, end = path.find('\\\\'), path.find('.')\n        beg = re.search(r\"\\d\",path).start()-1\n        end = path.find('.')\n        idx, rating = path[beg+1:end].split('_')\n        train_df.append([text, rating])\n        \n        \n        \nfor path in tqdm(test_pos, desc='Getting positive test data', position=0):\n    with open(path, encoding=\"utf8\") as f:\n        text = f.read()\n        #beg, end = path.find('\\\\'), path.find('.')\n        beg = re.search(r\"\\d\",path).start()-1\n        end = path.find('.')\n        idx, rating = path[beg+1:end].split('_')\n        test_df.append([text, rating])\n        \n        \n        \nfor path in tqdm(test_neg, desc='Getting negative test data', position=0):\n    with open(path, encoding=\"utf8\") as f:\n        text = f.read()\n        #beg, end = path.find('\\\\'), path.find('.')\n        beg = re.search(r\"\\d\",path).start()-1\n        end = path.find('.')\n        idx, rating = path[beg+1:end].split('_')\n        test_df.append([text, rating])"},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":"train_df = pd.DataFrame(train_df, columns=['text', 'rating'])\ntest_df = pd.DataFrame(test_df, columns=['text', 'rating'])"},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Records:  50000\n"},{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>I guess this movie will only work on people wh...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A great film this, and a shame that it will re...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Christopher Lloyd is funny and really believab...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>This is a thinking man's silly movie. If you d...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Daniel Day Lewis is one of the best actors of ...</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                                text rating\n0  I guess this movie will only work on people wh...      7\n1  A great film this, and a shame that it will re...      8\n2  Christopher Lloyd is funny and really believab...      9\n3  This is a thinking man's silly movie. If you d...     10\n4  Daniel Day Lewis is one of the best actors of ...     10"},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":"print('Records: ', train_df.size)\ntrain_df.head()"},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Number of reviews with rating 1: 5100\nNumber of reviews with rating 2: 2284\nNumber of reviews with rating 3: 2420\nNumber of reviews with rating 4: 2696\nNumber of reviews with rating 5: 0\nNumber of reviews with rating 6: 0\nNumber of reviews with rating 7: 2496\nNumber of reviews with rating 8: 3009\nNumber of reviews with rating 9: 2263\nNumber of reviews with rating 10: 4732\n"}],"source":"for i in range(1, 11):\n    print(f'Number of reviews with rating {i}: {train_df[train_df.rating == str(i)].shape[0]}')"},{"cell_type":"markdown","metadata":{},"source":"### *We might consider (?or not?) only movies with reviews 1(terrible) and 10(perfect)"},{"cell_type":"markdown","metadata":{},"source":"# 2. Clean and Preprocess"},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":"def regex(text):\n    text = re.sub(r'[^\\w\\s]', '', text.lower())\n    return text"},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"CPU times: user 2.74 s, sys: 7.95 ms, total: 2.75 s\nWall time: 2.75 s\n"}],"source":"%%time\n# Remove punctuaction and lower all texts\ntrain_df.text = train_df.text.apply(lambda row: regex(row))\ntest_df.text = test_df.text.apply(lambda row: regex(row))"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>i guess this movie will only work on people wh...</td>\n      <td>7</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>a great film this and a shame that it will rec...</td>\n      <td>8</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>christopher lloyd is funny and really believab...</td>\n      <td>9</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>this is a thinking mans silly movie if you don...</td>\n      <td>10</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>daniel day lewis is one of the best actors of ...</td>\n      <td>10</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"                                                text rating\n0  i guess this movie will only work on people wh...      7\n1  a great film this and a shame that it will rec...      8\n2  christopher lloyd is funny and really believab...      9\n3  this is a thinking mans silly movie if you don...     10\n4  daniel day lewis is one of the best actors of ...     10"},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":"train_df.head()"},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"0        i guess this movie will only work on people wh...\n1        a great film this and a shame that it will rec...\n2        christopher lloyd is funny and really believab...\n3        this is a thinking mans silly movie if you don...\n4        daniel day lewis is one of the best actors of ...\n                               ...                        \n24995    i understand what this movie was trying to por...\n24996    a friend of mine bought this very cheaply and ...\n24997    my friends and i rented this for bad movie nig...\n24998    moron and girlfriend conduct some ritual to re...\n24999    ok people honestly this gotta be one of the wo...\nName: text, Length: 25000, dtype: object\n"}],"source":"print(train_df.text)"},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":"consider only rating 1 and 10\nbayes_df_train = train_df[(train_df.rating == '1') | (train_df.rating == '10')]\nbayes_df_test = test_df[(test_df.rating == '1') | (test_df.rating == '10')]\nGOOD_WORDS = defaultdict(int)\nBAD_WORDS = defaultdict(int)"},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":"for index, row in tqdm(bayes_df_train.iterrows(), desc='Creating Bayes dictionaries', position=0):\n    text, rating = row['text'], row['rating']\n    \n    for word in text.split():\n        if rating == '10':\n            GOOD_WORDS[word] += 1\n        else:\n            BAD_WORDS[word] += 1"},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":"# most frequent GOOD words\nlist(sorted(GOOD_WORDS.items(), key=lambda x: x[1], reverse=True))[:10]"},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":"# most frequent BAD words\nlist(sorted(BAD_WORDS.items(), key=lambda x: x[1], reverse=True))[:10]"},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":"def classify(text, target_dict):\n    text = regex(text)\n    \n    for word in text.split():\n        if not word in target_dict:\n            target_dict[word] = 1\n            \n    sum_of_all = sum(target_dict.values())\n    \n    ppd = 0\n    for word in text.split():\n        ppd += np.log2(float(target_dict[word]) / sum_of_all)\n        \n    return ppd\n    \n    \ndef predict(text):\n    ppd_good = classify(text, GOOD_WORDS)\n    ppd_bad = classify(text, BAD_WORDS)\n\n    \n    all_ppd = np.array([ppd_good, ppd_bad])\n    target = ['10', '1'][np.argmax(all_ppd)]\n    \n    return target"},{"cell_type":"markdown","metadata":{},"source":"### 3.1 Checking train accuracy"},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":"correct, wrong = 0, 0\nreal_targets, predictions = [], []\n\nfor index, row in tqdm(bayes_df_train.iterrows(), desc='Checking train accuracy', position=0):\n    text, rating = row['text'], row['rating']\n    \n    pred = predict(text)\n    real_targets.append(rating)\n    predictions.append(pred)\n    if pred == rating:\n        correct += 1\n    else:\n        wrong += 1\n        \n   if pred == '10' and rating == '1':\n       FP += 1"},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":"print(f'Correct: {correct}, Wrong: {wrong}')\nprint(f'Accuracy: {correct / (wrong + correct) * 100}%')\n\nM = metrics.confusion_matrix(predictions, real_targets)\nprint('\\nConfusion matrix:')\nprint(M)\nprint(f'\\nTrue negative (rating = 1): {M[0][0]}')\nprint(f'True positive (rating = 10): {M[1][1]}')\nprint(f'False negative: {M[0][1]}')\nprint(f'False positive: {M[1][0]}')"},{"cell_type":"markdown","metadata":{},"source":["*So we are rather sceptic and most of our mistakes are movies which are good, but we classify them as bad."]},{"cell_type":"markdown","metadata":{},"source":"### 3.2 Checking test accuracy"},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":"correct, wrong = 0, 0\nreal_targets, predictions = [], []\n\nfor index, row in tqdm(bayes_df_test.iterrows(), desc='Checking test accuracy', position=0):\n    text, rating = row['text'], row['rating']\n    \n    pred = predict(text)\n    real_targets.append(rating)\n    predictions.append(pred)\n\n    if pred == rating:\n        correct += 1\n    else:\n        wrong += 1"},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":"print(f'Correct: {correct}, Wrong: {wrong}')\nprint(f'Accuracy: {correct / (wrong + correct) * 100}%')\n\nM = metrics.confusion_matrix(predictions, real_targets)\nprint('\\nConfusion matrix:')\nprint(M)\nprint(f'\\nTrue negative (rating = 1): {M[0][0]}')\nprint(f'True positive (rating = 10): {M[1][1]}')\nprint(f'False negative: {M[0][1]}')\nprint(f'False positive: {M[1][0]}')"},{"cell_type":"markdown","metadata":{},"source":"*Again we are sceptic"},{"cell_type":"markdown","execution_count":10,"metadata":{},"outputs":[],"source":"# 5. sklearn built in Logistic Regression"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"### 5.1 Data vectorization (one-hot encoding)"},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":"reviews_train_clean = np.array(train_df.text)\nreviews_test_clean = np.array(test_df.text)\ncv = CountVectorizer(binary=True)\ncv.fit(reviews_train_clean)\nX = cv.transform(reviews_train_clean)\nX_test = cv.transform(reviews_test_clean)     "},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"Accuracy for C=0.01: 0.86768\nAccuracy for C=0.05: 0.87632\nAccuracy for C=0.25: 0.8768\nAccuracy for C=0.5: 0.87568\nAccuracy for C=1: 0.87296\n"}],"source":"target = [1 if i < 12500 else 0 for i in range(25000)]\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, target, train_size = 0.75\n)\n\nfor c in [0.01, 0.05, 0.25, 0.5, 1]:    \n    lr = LogisticRegression(C=c,max_iter=300) # pobawic sie parametrami znalezc najlepsze\n    lr.fit(X_train, y_train)\n    print (\"Accuracy for C=%s: %s\" \n           % (c, accuracy_score(y_val, lr.predict(X_val))))"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"# 6. pure Logistic Regression"},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":"def sigmoid(x):\n    return 1 / (1 + np.exp(-x))"},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":"def logreg_loss(Theta, X, Y):\n    Z = Theta.T.dot(X)\n    nll = -np.sum([\n                    y * np.log2(sigmoid(Z)) \\\n                    + (1-y) * np.log2(1 - sigmoid(Z)) \\\n                    for y in Y\n                    ])\n    \n    grad = X.dot((sigmoid(Z) - Y).T)\n    return nll, grad.reshape(Theta.shape)\n"},{"cell_type":"markdown","execution_count":null,"metadata":{},"outputs":[],"source":"### 6.1. Data vectorization (one-hot encoding)"},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":"reviews_train_clean = np.array(train_df.text)\nreviews_test_clean = np.array(test_df.text)\ncv = CountVectorizer(binary=True)\ncv.fit(reviews_train_clean)\nX = cv.transform(reviews_train_clean)\nX_test = cv.transform(reviews_test_clean)   "},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":"\ntarget = [1 if i < 12500 else 0 for i in range(25000)]\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, target, train_size = 0.75\n)"},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":"def logreg_classify(Theta,x):\n    return (Theta.T.dot(x) >= 0)\n\ndef logreg_predict(Theta,Xs):\n    return [logreg_classify(Theta,x) for x in Xs]"},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"(18750, 121004)\n"}],"source":"print(X_train.shape)"},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[],"source":"Theta0 = np.ones((X_train.shape[1]))\nThetaOpt = sopt.fmin_l_bfgs_b(lambda Theta: logreg_loss(Theta, X_train, y_train), np.array(Theta0),maxiter=100,maxfun=100,factr=1e12)[0] #liczy w nieskonczonosc albo bardzo długo"},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":"\n"}],"source":"print (\"Accuracy: %s\"  % accuracy_score(y_val, logreg_predict(ThetaOpt,X_val)))"}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"name":"python","codemirror_mode":{"name":"ipython","version":3}},"orig_nbformat":2,"file_extension":".py","mimetype":"text/x-python","name":"python","npconvert_exporter":"python","pygments_lexer":"ipython3","version":3}}