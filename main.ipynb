{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import string \n",
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import scipy.optimize as sopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Macro for windows / mac users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = 'Mac'\n",
    "# system = 'Win'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparing data (IMDb movies' reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_path = 'data_sets/aclImdb/train/pos/*'\n",
    "train_neg_path = 'data_sets/aclImdb/train/neg/*'\n",
    "\n",
    "train_pos = glob.glob(train_pos_path)\n",
    "train_neg = glob.glob(train_neg_path)\n",
    "\n",
    "\n",
    "test_pos_path = 'data_sets/aclImdb/test/pos/*'\n",
    "test_neg_path = 'data_sets/aclImdb/test/neg/*'\n",
    "\n",
    "test_pos = glob.glob(test_pos_path)\n",
    "test_neg = glob.glob(test_neg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                    \r"
     ]
    }
   ],
   "source": [
    "train_df = []\n",
    "test_df = []\n",
    "\n",
    "for path in tqdm(train_pos, desc='Getting positive train data', position=0, leave=False):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "        \n",
    "#         For win users\n",
    "        if system == 'Win':\n",
    "            beg, end = path.find('\\\\'), path.find('.')\n",
    "        \n",
    "#         For mac users\n",
    "        if system == 'Mac':\n",
    "            beg = re.search(r\"\\d\",path).start()-1\n",
    "            end = path.find('.')\n",
    "            \n",
    "        idx, rating = path[beg+1:-4].split('_')\n",
    "        train_df.append([text, rating])\n",
    "        \n",
    "for path in tqdm(train_neg, desc='Getting negative train data', position=0, leave=False):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "        \n",
    "#         For win users\n",
    "        if system == 'Win':\n",
    "            beg, end = path.find('\\\\'), path.find('.')\n",
    "        \n",
    "#         For mac users\n",
    "        if system == 'Mac':\n",
    "            beg = re.search(r\"\\d\",path).start()-1\n",
    "            end = path.find('.')\n",
    "\n",
    "        idx, rating = path[beg+1:-4].split('_')\n",
    "        train_df.append([text, rating])\n",
    "         \n",
    "for path in tqdm(test_pos, desc='Getting positive test data', position=0, leave=False):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "        \n",
    "#         For win users\n",
    "        if system == 'Win':\n",
    "            beg, end = path.find('\\\\'), path.find('.')\n",
    "        \n",
    "#         For mac users\n",
    "        if system == 'Mac':\n",
    "            beg = re.search(r\"\\d\",path).start()-1\n",
    "            end = path.find('.')\n",
    "            \n",
    "        idx, rating = path[beg+1:-4].split('_')\n",
    "        test_df.append([text, rating])\n",
    "   \n",
    "for path in tqdm(test_neg, desc='Getting negative test data', position=0, leave=False):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "\n",
    "#         For win users\n",
    "        if system == 'Win':\n",
    "            beg, end = path.find('\\\\'), path.find('.')\n",
    "        \n",
    "#         For mac users\n",
    "        if system == 'Mac':\n",
    "            beg = re.search(r\"\\d\",path).start()-1\n",
    "            end = path.find('.')\n",
    "            \n",
    "        idx, rating = path[beg+1:-4].split('_')\n",
    "        test_df.append([text, rating])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_df, columns=['text', 'rating'])\n",
    "test_df = pd.DataFrame(test_df, columns=['text', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records:  50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For a movie that gets no respect there sure ar...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bizarre horror movie filled with famous faces ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A solid, if unremarkable film. Matthau, as Ein...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's a strange feeling to sit alone in a theat...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You probably all already know this by now, but...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text rating\n",
       "0  For a movie that gets no respect there sure ar...      9\n",
       "1  Bizarre horror movie filled with famous faces ...      8\n",
       "2  A solid, if unremarkable film. Matthau, as Ein...      7\n",
       "3  It's a strange feeling to sit alone in a theat...      8\n",
       "4  You probably all already know this by now, but...     10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Records: ', train_df.size)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews with rating 1: 5100\n",
      "Number of reviews with rating 2: 2284\n",
      "Number of reviews with rating 3: 2420\n",
      "Number of reviews with rating 4: 2696\n",
      "Number of reviews with rating 5: 0\n",
      "Number of reviews with rating 6: 0\n",
      "Number of reviews with rating 7: 2496\n",
      "Number of reviews with rating 8: 3009\n",
      "Number of reviews with rating 9: 2263\n",
      "Number of reviews with rating 10: 4732\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    print(f'Number of reviews with rating {i}: {train_df[train_df.rating == str(i)].shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *We might consider (?or not?) only movies with reviews 1(terrible) and 10(perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.21 s, sys: 33.7 ms, total: 2.24 s\n",
      "Wall time: 2.25 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Remove punctuaction and lower all texts\n",
    "train_df.text = train_df.text.apply(lambda row: regex(row))\n",
    "test_df.text = test_df.text.apply(lambda row: regex(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>for a movie that gets no respect there sure ar...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bizarre horror movie filled with famous faces ...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a solid if unremarkable film matthau as einste...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>its a strange feeling to sit alone in a theate...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you probably all already know this by now but ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text rating\n",
       "0  for a movie that gets no respect there sure ar...      9\n",
       "1  bizarre horror movie filled with famous faces ...      8\n",
       "2  a solid if unremarkable film matthau as einste...      7\n",
       "3  its a strange feeling to sit alone in a theate...      8\n",
       "4  you probably all already know this by now but ...     10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        for a movie that gets no respect there sure ar...\n",
      "1        bizarre horror movie filled with famous faces ...\n",
      "2        a solid if unremarkable film matthau as einste...\n",
      "3        its a strange feeling to sit alone in a theate...\n",
      "4        you probably all already know this by now but ...\n",
      "                               ...                        \n",
      "24995    my comments may be a bit of a spoiler for what...\n",
      "24996    the saucy misadventures of four au pairs who a...\n",
      "24997    oh those italians assuming that movies about a...\n",
      "24998    eight academy nominations its beyond belief i ...\n",
      "24999    not that i dislike childrens movies but this w...\n",
      "Name: text, Length: 25000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(train_df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider only rating 1 and 10\n",
    "bayes_df_train = train_df[(train_df.rating == '1') | (train_df.rating == '10')]\n",
    "bayes_df_test = test_df[(test_df.rating == '1') | (test_df.rating == '10')]\n",
    "GOOD_WORDS = defaultdict(int)\n",
    "BAD_WORDS = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Bayes dictionaries: 9832it [00:02, 3821.57it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(bayes_df_train.iterrows(), desc='Creating Bayes dictionaries', position=0):\n",
    "    text, rating = row['text'], row['rating']\n",
    "    \n",
    "    for word in text.split():\n",
    "        if rating == '10':\n",
    "            GOOD_WORDS[word] += 1\n",
    "        else:\n",
    "            BAD_WORDS[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 56972),\n",
       " ('and', 30301),\n",
       " ('a', 26016),\n",
       " ('of', 25791),\n",
       " ('to', 22249),\n",
       " ('is', 19380),\n",
       " ('in', 16257),\n",
       " ('i', 14729),\n",
       " ('it', 14595),\n",
       " ('this', 13341)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent GOOD words\n",
    "list(sorted(GOOD_WORDS.items(), key=lambda x: x[1], reverse=True))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 58427),\n",
       " ('a', 28386),\n",
       " ('and', 26617),\n",
       " ('to', 26292),\n",
       " ('of', 25218),\n",
       " ('is', 18370),\n",
       " ('this', 18239),\n",
       " ('i', 17985),\n",
       " ('it', 15645),\n",
       " ('in', 15538)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent BAD words\n",
    "list(sorted(BAD_WORDS.items(), key=lambda x: x[1], reverse=True))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text, target_dict):\n",
    "    text = regex(text)\n",
    "    \n",
    "    for word in text.split():\n",
    "        if not word in target_dict:\n",
    "            target_dict[word] = 1\n",
    "            \n",
    "    sum_of_all = sum(target_dict.values())\n",
    "    \n",
    "    ppd = 0\n",
    "    for word in text.split():\n",
    "        ppd += np.log2(float(target_dict[word]) / sum_of_all)\n",
    "        \n",
    "    return ppd\n",
    "    \n",
    "    \n",
    "def predict(text):\n",
    "    ppd_good = classify(text, GOOD_WORDS)\n",
    "    ppd_bad = classify(text, BAD_WORDS)\n",
    "    \n",
    "    all_ppd = np.array([ppd_good, ppd_bad])\n",
    "    target = ['10', '1'][np.argmax(all_ppd)]\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Checking train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking train accuracy: 9832it [00:28, 345.33it/s]\n"
     ]
    }
   ],
   "source": [
    "correct, wrong = 0, 0\n",
    "real_targets, predictions = [], []\n",
    "\n",
    "for index, row in tqdm(bayes_df_train.iterrows(), desc='Checking train accuracy', position=0):\n",
    "    text, rating = row['text'], row['rating']\n",
    "    \n",
    "    pred = predict(text)\n",
    "    real_targets.append(rating)\n",
    "    predictions.append(pred)\n",
    "    if pred == rating:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 9362, Wrong: 470\n",
      "Accuracy: 95.21969080553295%\n",
      "\n",
      "Confusion matrix:\n",
      "[[4933  303]\n",
      " [ 167 4429]]\n",
      "\n",
      "True negative (rating = 1): 4933\n",
      "True positive (rating = 10): 4429\n",
      "False negative: 303\n",
      "False positive: 167\n"
     ]
    }
   ],
   "source": [
    "print(f'Correct: {correct}, Wrong: {wrong}')\n",
    "print(f'Accuracy: {correct / (wrong + correct) * 100}%')\n",
    "\n",
    "M = metrics.confusion_matrix(predictions, real_targets)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*So we are rather sceptic and most of our mistakes are movies which are good, but we classify them as bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Checking test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking test accuracy: 10021it [00:33, 297.44it/s]\n"
     ]
    }
   ],
   "source": [
    "correct, wrong = 0, 0\n",
    "real_targets, predictions = [], []\n",
    "\n",
    "for index, row in tqdm(bayes_df_test.iterrows(), desc='Checking test accuracy', position=0):\n",
    "    text, rating = row['text'], row['rating']\n",
    "    \n",
    "    pred = predict(text)\n",
    "    real_targets.append(rating)\n",
    "    predictions.append(pred)\n",
    "\n",
    "    if pred == rating:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 8901, Wrong: 1120\n",
      "Accuracy: 88.82347071150583%\n",
      "\n",
      "Confusion matrix:\n",
      "[[4689  787]\n",
      " [ 333 4212]]\n",
      "\n",
      "True negative (rating = 1): 4689\n",
      "True positive (rating = 10): 4212\n",
      "False negative: 787\n",
      "False positive: 333\n"
     ]
    }
   ],
   "source": [
    "print(f'Correct: {correct}, Wrong: {wrong}')\n",
    "print(f'Accuracy: {correct / (wrong + correct) * 100}%')\n",
    "\n",
    "M = metrics.confusion_matrix(predictions, real_targets)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Again we are sceptic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5 Class Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive_Bayes:\n",
    "    def __init__(self,alpha=0,fit_prior=True,class_prior=None):\n",
    "        self.alpha = alpha\n",
    "        self.fit_prior = fit_prior\n",
    "        self.class_prior_array = class_prior\n",
    "        if class_prior:\n",
    "            self.fit_prior = False\n",
    "    \n",
    "    \n",
    "    def fit(self,X,y):\n",
    "        self.classes,prior = np.unique(y,return_counts=True)\n",
    "        self.N = len(y)\n",
    "        \n",
    "        # Setting class prior\n",
    "        if self.fit_prior:\n",
    "            self.class_prior = {class_ : np.log(prior[i]/self.N + 1e-100) for i,class_ in enumerate(self.classes)}\n",
    "        elif self.class_prior_array:\n",
    "            self.class_prior = {class_ : np.log(self.class_prior_array[i] + 1e-100) for i,class_ in enumerate(self.classes)}\n",
    "        else:\n",
    "            self.class_prior = {class_ : np.log(1/len(self.classes) + 1e-100) for class_ in self.classes}\n",
    "            \n",
    "        # Creating words dictionaries\n",
    "        self.class_words_counts = {class_ : defaultdict(lambda: 0) for class_ in self.classes}\n",
    "        for i,text in enumerate(X):\n",
    "            target = y[i]\n",
    "            for word in text.split():\n",
    "                self.class_words_counts[target][word] += 1\n",
    "        \n",
    "        # Creating probabilities dictionaries\n",
    "        self.class_words_probs = {class_ : defaultdict(lambda: np.log(self.alpha + 1e-100)) for class_ in self.classes}\n",
    "        for class_,dict_ in self.class_words_counts.items():\n",
    "            for word,count in dict_.items():\n",
    "                self.class_words_probs[class_][word] = np.log(count + 1e-100)\n",
    "    \n",
    "        self.class_words_amount = {class_ : np.log(sum(self.class_words_counts[class_].values())) for class_ in self.classes}\n",
    "    \n",
    "\n",
    "    def get_class_log_probabilities(self,text):\n",
    "        probs = {class_ : 0 for class_ in self.classes}\n",
    "        for class_ in self.classes:\n",
    "            for word in text.split():\n",
    "                probs[class_] += self.class_words_probs[class_][word]\n",
    "                probs[class_] -= self.class_words_amount[class_]\n",
    "            probs[class_] += self.class_prior[class_]\n",
    "        return probs\n",
    "    \n",
    "    \n",
    "    def predict(self,X,return_probabilities = False):\n",
    "        preds = []\n",
    "        preds_probs = []\n",
    "        for text in X:\n",
    "            prob = self.get_class_log_probabilities(text)\n",
    "            #prob = {class_ : np.exp(pbb) for class_,pbb in prob.items()}\n",
    "            preds_probs.append(prob)\n",
    "            pred = max(prob,key = prob.get)\n",
    "            preds.append(pred)\n",
    "        \n",
    "        if return_probabilities:\n",
    "            return preds,preds_probs\n",
    "        return preds\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayes_df_train = train_df[(train_df.rating == '1') | (train_df.rating == '10')]\n",
    "bayes_df_test = test_df[(test_df.rating == '1') | (test_df.rating == '10')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,y_train = np.array(bayes_df_train['text']),np.array(bayes_df_train['rating'])\n",
    "X_test,y_test = np.array(bayes_df_test['text']),np.array(bayes_df_test['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.0\n",
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,ppb = NB.predict(X_train,return_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN, alpha : 1.0\n",
      "Acc: 0.9491456468673718\n",
      "\n",
      "Confusion matrix:\n",
      "[[4963  363]\n",
      " [ 137 4369]]\n",
      "\n",
      "True negative (rating = 1): 4963\n",
      "True positive (rating = 10): 4369\n",
      "False negative: 363\n",
      "False positive: 137\n"
     ]
    }
   ],
   "source": [
    "print(f\"TRAIN, alpha : {alpha}\")\n",
    "print(f\"Acc: {np.mean(predictions == y_train)}\")\n",
    "M = metrics.confusion_matrix(predictions, y_train)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,ppb = NB.predict(X_test,return_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.0\n",
      "Acc: 0.8884342879952101\n",
      "\n",
      "Confusion matrix:\n",
      "[[4660  756]\n",
      " [ 362 4243]]\n",
      "\n",
      "True negative (rating = 1): 4660\n",
      "True positive (rating = 10): 4243\n",
      "False negative: 756\n",
      "False positive: 362\n"
     ]
    }
   ],
   "source": [
    "print(f\"TEST, alpha : {alpha}\")\n",
    "print(f\"Acc: {np.mean(predictions == y_test)}\")\n",
    "M = metrics.confusion_matrix(predictions, y_test)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.0\n",
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,ppb = NB.predict(X_train,return_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN, alpha : 0.0\n",
      "Acc: 0.9899308380797396\n",
      "\n",
      "Confusion matrix:\n",
      "[[5092   91]\n",
      " [   8 4641]]\n",
      "\n",
      "True negative (rating = 1): 5092\n",
      "True positive (rating = 10): 4641\n",
      "False negative: 91\n",
      "False positive: 8\n"
     ]
    }
   ],
   "source": [
    "print(f\"TRAIN, alpha : {alpha}\")\n",
    "print(f\"Acc: {np.mean(predictions == y_train)}\")\n",
    "M = metrics.confusion_matrix(predictions, y_train)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions,ppb = NB.predict(X_test,return_probabilities=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 0.0\n",
      "Acc: 0.7240794331903003\n",
      "\n",
      "Confusion matrix:\n",
      "[[3932 1675]\n",
      " [1090 3324]]\n",
      "\n",
      "True negative (rating = 1): 3932\n",
      "True positive (rating = 10): 3324\n",
      "False negative: 1675\n",
      "False positive: 1090\n"
     ]
    }
   ],
   "source": [
    "print(f\"TEST, alpha : {alpha}\")\n",
    "print(f\"Acc: {np.mean(predictions == y_test)}\")\n",
    "M = metrics.confusion_matrix(predictions, y_test)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha : 0.0, test acc: 0.7240794331903003\n",
      "Alpha : 0.25, test acc: 0.8820476998303562\n",
      "Alpha : 0.5, test acc: 0.8868376409539966\n",
      "Alpha : 0.75, test acc: 0.8882347071150584\n",
      "Alpha : 1.0, test acc: 0.8884342879952101\n",
      "Alpha : 1.25, test acc: 0.8881349166749826\n",
      "Alpha : 1.5, test acc: 0.8893324019558926\n",
      "Alpha : 1.75, test acc: 0.8884342879952101\n",
      "Alpha : 2.0, test acc: 0.8882347071150584\n",
      "Alpha : 3.0, test acc: 0.8872368027142999\n",
      "Alpha : 4.0, test acc: 0.8862388983135415\n",
      "Alpha : 5.0, test acc: 0.8830456042311147\n",
      "Alpha : 10.0, test acc: 0.8759604829857299\n"
     ]
    }
   ],
   "source": [
    "for alpha in [0.0,0.25,0.5,0.75,1.0,1.25,1.5,1.75,2.0,3.0,4.0,5.0,10.0]:\n",
    "    NB = Naive_Bayes(fit_prior = False,alpha=alpha)\n",
    "    NB.fit(X_train,y_train)\n",
    "    predictions,ppb = NB.predict(X_test,return_probabilities=True)\n",
    "    acc = np.mean(predictions == y_test)\n",
    "    print(f'Alpha : {alpha}, test acc: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can consider if stemming or removing stop words can imporove accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For stemming we will use Snowball Stemming (Porter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_(text):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(text):\n",
    "    return ' '.join([word for word in text.split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem_and_remove_stop_words(text):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split() if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_train_df = bayes_df_train.copy()\n",
    "stemmed_test_df = bayes_df_test.copy()\n",
    "stemmed_train_df.text = stemmed_train_df.text.apply(lambda row: stem_(row))\n",
    "stemmed_test_df.text = stemmed_test_df.text.apply(lambda row: stem_(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "swr_train_df = bayes_df_train.copy()\n",
    "swr_test_df = bayes_df_test.copy()\n",
    "swr_train_df.text = swr_train_df.text.apply(lambda row: remove_stop_words(row))\n",
    "swr_test_df.text = swr_test_df.text.apply(lambda row: remove_stop_words(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmed_swr_train_df = bayes_df_train.copy()\n",
    "stemmed_swr_test_df = bayes_df_test.copy()\n",
    "stemmed_swr_train_df.text = stemmed_swr_train_df.text.apply(lambda row: stem_(row))\n",
    "stemmed_swr_test_df.text = stemmed_swr_test_df.text.apply(lambda row: stem_(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.5, stemmed\n",
      "Acc: 0.8827462329108872\n",
      "\n",
      "Confusion matrix:\n",
      "[[4623  776]\n",
      " [ 399 4223]]\n",
      "\n",
      "True negative (rating = 1): 4623\n",
      "True positive (rating = 10): 4223\n",
      "False negative: 776\n",
      "False positive: 399\n"
     ]
    }
   ],
   "source": [
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)\n",
    "NB.fit(np.array(stemmed_train_df['text']),np.array(stemmed_train_df['rating']))\n",
    "predictions = NB.predict(np.array(stemmed_test_df['text']))\n",
    "print(f\"TEST, alpha : {alpha}, stemmed\")\n",
    "print(f\"Acc: {np.mean(predictions == np.array(stemmed_test_df['rating']))}\")\n",
    "M = metrics.confusion_matrix(predictions, np.array(stemmed_test_df['rating']))\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.5, stop words removed\n",
      "Acc: 0.8995110268436284\n",
      "\n",
      "Confusion matrix:\n",
      "[[4656  641]\n",
      " [ 366 4358]]\n",
      "\n",
      "True negative (rating = 1): 4656\n",
      "True positive (rating = 10): 4358\n",
      "False negative: 641\n",
      "False positive: 366\n"
     ]
    }
   ],
   "source": [
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)\n",
    "NB.fit(np.array(swr_train_df['text']),np.array(swr_test_df['rating']))\n",
    "predictions = NB.predict(np.array(swr_test_df['text']))\n",
    "print(f\"TEST, alpha : {alpha}, stop words removed\")\n",
    "print(f\"Acc: {np.mean(predictions == np.array(swr_test_df['rating']))}\")\n",
    "M = metrics.confusion_matrix(predictions, np.array(swr_test_df['rating']))\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST, alpha : 1.5, stemmed and stop words removed\n",
      "Acc: 0.8827462329108872\n",
      "\n",
      "Confusion matrix:\n",
      "[[4623  776]\n",
      " [ 399 4223]]\n",
      "\n",
      "True negative (rating = 1): 4623\n",
      "True positive (rating = 10): 4223\n",
      "False negative: 776\n",
      "False positive: 399\n"
     ]
    }
   ],
   "source": [
    "NB = Naive_Bayes(fit_prior = False,alpha=alpha)\n",
    "NB.fit(np.array(stemmed_swr_train_df['text']),np.array(stemmed_swr_train_df['rating']))\n",
    "predictions = NB.predict(np.array(stemmed_swr_test_df['text']))\n",
    "print(f\"TEST, alpha : {alpha}, stemmed and stop words removed\")\n",
    "print(f\"Acc: {np.mean(predictions == np.array(stemmed_swr_test_df['rating']))}\")\n",
    "M = metrics.confusion_matrix(predictions, np.array(stemmed_swr_test_df['rating']))\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. sklearn built in Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Data vectorization (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.5 s, sys: 265 ms, total: 17.8 s\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "reviews_train_clean = np.array(train_df.text)\n",
    "reviews_test_clean = np.array(test_df.text)\n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv.fit(reviews_train_clean)\n",
    "\n",
    "X = cv.transform(reviews_train_clean)\n",
    "X_test = cv.transform(reviews_test_clean)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for C=0.01: 0.86864\n",
      "Accuracy for C=0.05: 0.88048\n",
      "Accuracy for C=0.25: 0.87984\n",
      "Accuracy for C=0.5: 0.87568\n",
      "Accuracy for C=1: 0.87536\n",
      "Accuracy for C=5: 0.87264\n",
      "CPU times: user 1min 26s, sys: 10.4 s, total: 1min 36s\n",
      "Wall time: 34.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "target = [1 if i < 12500 else 0 for i in range(25000)]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, target, train_size = 0.75\n",
    ")\n",
    "\n",
    "for c in [0.01, 0.05, 0.25, 0.5, 1, 5]:    \n",
    "    lr = LogisticRegression(C=c, max_iter=500, solver='lbfgs')\n",
    "    lr.fit(X_train, y_train)\n",
    "    print (\"Accuracy for C=%s: %s\" \n",
    "           % (c, accuracy_score(y_val, lr.predict(X_val))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing\n",
    "Removing stop words, stemming, encode review as a vector of words occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will be using reviews with rating equal 1 or 10 from training set. \n",
    "# Test samples rating will be also classified as 1 or 10\n",
    "\n",
    "LR_train_df = train_df[(train_df.rating == '1') | (train_df.rating == '10')]\n",
    "LR_test_df = test_df[(test_df.rating == '1') | (test_df.rating == '10')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_train_target = np.array([int(r) for r in LR_train_df['rating']]) // 10\n",
    "LR_test_target = np.array([int(r) for r in LR_test_df['rating']]) // 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9832, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_train_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/febrin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "stemmer = SnowballStemmer(\"english\")\n",
    "nltk.download('stopwords')\n",
    "stopwords_set = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(sample):\n",
    "    words = sample.split()\n",
    "    words = [ stemmer.stem(word) for word in words if word not in stopwords_set ]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample from train set\n",
    "sample = '''brilliant overacting by lesley ann warren best dramatic hobo lady i \n",
    "have ever seen and love scenes in clothes warehouse are second to none the corn \n",
    "on face is a classic as good as anything in blazing saddles the take on lawyers \n",
    "is also superb after being accused of being a turncoat selling out his boss and \n",
    "being dishonest the lawyer of pepto bolt shrugs indifferently im a lawyer he says \n",
    "three funny words jeffrey tambor a favorite from the later larry sanders show is \n",
    "fantastic here too as a mad millionaire who wants to crush the ghetto his character \n",
    "is more malevolent than usual the hospital scene and the scene where the homeless \n",
    "invade a demolition site are alltime classics look for the legs scene and the two \n",
    "big diggers fighting one bleeds this movie gets better each time i see it which is \n",
    "quite often'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brilliant overact lesley ann warren best dramat hobo ladi ever seen love scene cloth warehous second none corn face classic good anyth blaze saddl take lawyer also superb accus turncoat sell boss dishonest lawyer pepto bolt shrug indiffer im lawyer say three funni word jeffrey tambor favorit later larri sander show fantast mad millionair want crush ghetto charact malevol usual hospit scene scene homeless invad demolit site alltim classic look leg scene two big digger fight one bleed movi get better time see quit often'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(preprocess(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCountVectorizer:\n",
    "    def __init__(self, min_df=-1, max_df=1e18, binary=False):\n",
    "        self.min_df = min_df\n",
    "        self.max_df = max_df\n",
    "        self.binary = binary\n",
    "    \n",
    "    def fit(self, df):\n",
    "        words_cnt = defaultdict(int)\n",
    "        col = df.columns[0]\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            text = df.iloc[i][col]\n",
    "            for word in text.split():\n",
    "                words_cnt[word] += 1\n",
    "                \n",
    "        all_words = []\n",
    "        for word, cnt in words_cnt.items():\n",
    "            if self.min_df <= cnt <= self.max_df:\n",
    "                all_words.append(word)\n",
    "                \n",
    "        self.all_words_ids = {w:i for i,w in enumerate(all_words)}\n",
    "        self.width = len(all_words)\n",
    "        \n",
    "    \n",
    "    def transform(self, df):\n",
    "        col = df.columns[0]\n",
    "        count_matrix = np.zeros([len(df), self.width], \\\n",
    "                                dtype=np.int32)\n",
    "        \n",
    "        for i in range(len(df)):\n",
    "            text = df.iloc[i][col]\n",
    "            words_cnt = defaultdict(int)\n",
    "            \n",
    "            for word in text:\n",
    "                words_cnt[word] += 1\n",
    "            \n",
    "            for word, cnt in words_cnt.items():\n",
    "                if word in self.all_words_ids:\n",
    "                    pos = self.all_words_ids[word]\n",
    "                    if binary:\n",
    "                        count_matrix[i][pos] = cnt\n",
    "                    else:\n",
    "                        count_matrix[i][pos] = 1\n",
    "                    \n",
    "        return count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MyCountVectorizer(min_df=3)\n",
    "m.fit(LR_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupa = m.transform(LR_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9832, 36487)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dupa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Theta0 = np.ones(dupa.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_loss(Theta, X, Y):\n",
    "    print(f\"Loss calculating... \",end=\"\")\n",
    "    Z = np.dot(Theta,X.T)\n",
    "    print(f\" Z done... \",end=\"\")\n",
    "    SZ = sigmoid(Z)\n",
    "    nll = -np.sum([\n",
    "                    y * np.log2(SZ + 1e-100) \\\n",
    "                    + (1-y) * np.log2(1 - SZ + 1e-100) \\\n",
    "                    for y in Y\n",
    "                    ])\n",
    "    print(f\" nll done... \",end=\"\")\n",
    "    grad = np.dot(X.T, (SZ - Y).T )\n",
    "    print(f\" grad done... done \")\n",
    "    return nll, grad.reshape(Theta.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ThetaOpt = sopt.fmin_l_bfgs_b(lambda Theta: logreg_loss(Theta, dupa, LR_train_target), Theta0, maxiter=50)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.61972053,  0.05736236,  0.42113507, ...,  0.97861499,\n",
       "        0.97148722,  0.9822661 ])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ThetaOpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-3.619721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.057362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.421135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.947041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.512566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17381</th>\n",
       "      <td>0.996847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17382</th>\n",
       "      <td>0.991743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17383</th>\n",
       "      <td>0.978615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17384</th>\n",
       "      <td>0.971487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17385</th>\n",
       "      <td>0.982266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17386 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0     -3.619721\n",
       "1      0.057362\n",
       "2      0.421135\n",
       "3     -0.947041\n",
       "4      0.512566\n",
       "...         ...\n",
       "17381  0.996847\n",
       "17382  0.991743\n",
       "17383  0.978615\n",
       "17384  0.971487\n",
       "17385  0.982266\n",
       "\n",
       "[17386 rows x 1 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Theta_df = pd.DataFrame(ThetaOpt)\n",
    "Theta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv = Theta_df.to_csv(r'LR_ThetaOpt.csv', index = True, header=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>probabl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>alreadi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>addit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17380</th>\n",
       "      <td>frollo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17381</th>\n",
       "      <td>sineat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17382</th>\n",
       "      <td>maa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17383</th>\n",
       "      <td>aloi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17384</th>\n",
       "      <td>mcenro</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17385 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "0      probabl\n",
       "1      alreadi\n",
       "2         know\n",
       "3            5\n",
       "4        addit\n",
       "...        ...\n",
       "17380   frollo\n",
       "17381   sineat\n",
       "17382      maa\n",
       "17383     aloi\n",
       "17384   mcenro\n",
       "\n",
       "[17385 rows x 1 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_pd = pd.DataFrame(all_train_words)\n",
    "words_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_csv2 = words_pd.to_csv(r'LR_all_words.csv', index = True, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_test = vectorize(LR_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logreg_classify(Theta,x):\n",
    "    return (Theta.T.dot(x) >= 0)\n",
    "\n",
    "def logreg_predict(Theta,Xs):\n",
    "    return [logreg_classify(Theta,x) for x in Xs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7331603632372019\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: %s\"  % accuracy_score(LR_test_target, logreg_predict(ThetaOpt,vectorized_test)))"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
