{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "import string \n",
    "from collections import defaultdict\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preparing data (IMDb movies' reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_path = 'data_sets/movies/train/pos/*'\n",
    "train_neg_path = 'data_sets/movies/train/neg/*'\n",
    "\n",
    "train_pos = glob.glob(train_pos_path)\n",
    "train_neg = glob.glob(train_neg_path)\n",
    "\n",
    "\n",
    "test_pos_path = 'data_sets/movies/test/pos/*'\n",
    "test_neg_path = 'data_sets/movies/test/neg/*'\n",
    "\n",
    "test_pos = glob.glob(test_pos_path)\n",
    "test_neg = glob.glob(test_neg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_sets/movies/train/pos\\\\0_9.txt',\n",
       " 'data_sets/movies/train/pos\\\\10000_8.txt',\n",
       " 'data_sets/movies/train/pos\\\\10001_10.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_pos[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = []\n",
    "test_df = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Getting positive train data: 100%|████████████████████████████████████████████| 12500/12500 [00:01<00:00, 11491.88it/s]\n",
      "Getting negative train data: 100%|████████████████████████████████████████████| 12500/12500 [00:01<00:00, 11584.74it/s]\n",
      "Getting positive test data: 100%|█████████████████████████████████████████████| 12500/12500 [00:01<00:00, 11717.11it/s]\n",
      "Getting negative test data: 100%|█████████████████████████████████████████████| 12500/12500 [00:01<00:00, 11907.71it/s]\n"
     ]
    }
   ],
   "source": [
    "for path in tqdm(train_pos, desc='Getting positive train data', position=0):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "        beg, end = path.find('\\\\'), path.find('.')\n",
    "        idx, rating = path[beg+1:end].split('_')\n",
    "        train_df.append([text, rating])\n",
    "        \n",
    "        \n",
    "\n",
    "for path in tqdm(train_neg, desc='Getting negative train data', position=0):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "        beg, end = path.find('\\\\'), path.find('.')\n",
    "        idx, rating = path[beg+1:end].split('_')\n",
    "        train_df.append([text, rating])\n",
    "        \n",
    "        \n",
    "        \n",
    "for path in tqdm(test_pos, desc='Getting positive test data', position=0):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "        beg, end = path.find('\\\\'), path.find('.')\n",
    "        idx, rating = path[beg+1:end].split('_')\n",
    "        test_df.append([text, rating])\n",
    "        \n",
    "        \n",
    "        \n",
    "for path in tqdm(test_neg, desc='Getting negative test data', position=0):\n",
    "    with open(path, encoding=\"utf8\") as f:\n",
    "        text = f.read()\n",
    "        beg, end = path.find('\\\\'), path.find('.')\n",
    "        idx, rating = path[beg+1:end].split('_')\n",
    "        test_df.append([text, rating])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_df, columns=['text', 'rating'])\n",
    "test_df = pd.DataFrame(test_df, columns=['text', 'rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records:  50000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bromwell High is a cartoon comedy. It ran at t...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Homelessness (or Houselessness as George Carli...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brilliant over-acting by Lesley Ann Warren. Be...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is easily the most underrated film inn th...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This is not the typical Mel Brooks film. It wa...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text rating\n",
       "0  Bromwell High is a cartoon comedy. It ran at t...      9\n",
       "1  Homelessness (or Houselessness as George Carli...      8\n",
       "2  Brilliant over-acting by Lesley Ann Warren. Be...     10\n",
       "3  This is easily the most underrated film inn th...      7\n",
       "4  This is not the typical Mel Brooks film. It wa...      8"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Records: ', train_df.size)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews with rating 1: 5100\n",
      "Number of reviews with rating 2: 2284\n",
      "Number of reviews with rating 3: 2420\n",
      "Number of reviews with rating 4: 2696\n",
      "Number of reviews with rating 5: 0\n",
      "Number of reviews with rating 6: 0\n",
      "Number of reviews with rating 7: 2496\n",
      "Number of reviews with rating 8: 3009\n",
      "Number of reviews with rating 9: 2263\n",
      "Number of reviews with rating 10: 4732\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    print(f'Number of reviews with rating {i}: {train_df[train_df.rating == str(i)].shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *We might consider (?or not?) only movies with reviews 1(terrible) and 10(perfect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 Preparing data (Stanford Sentiment)\n",
    "### (or not because this DS doesn't make sense) \n",
    "**for eg. sentences:** <br/>\n",
    "' ( the cockettes ) provides a window into a subculture hell-bent on expressing itself in every way imaginable|5 <br/>\n",
    "' ( the cockettes ) provides a window into a subculture hell-bent on expressing itself in every way imaginable .|6 <br/>\n",
    "' ( the cockettes ) provides a window into a subculture hell-bent on expressing itself in every way imaginable . '|7 <br/>\n",
    "**Have sentiment:** <br/>\n",
    "5|0.375 <br/>\n",
    "6|0.41667 <br/> \n",
    "7|0.54167 <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_sets/stanfordSentiment/sentiment.txt') as f:\n",
    "    for line in f:\n",
    "        text, idx = line.split('|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Clean and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regex(text):\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Remove punctuaction and lower all texts\n",
    "train_df.text = train_df.text.apply(lambda row: regex(row))\n",
    "test_df.text = test_df.text.apply(lambda row: regex(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bromwell high is a cartoon comedy it ran at th...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>homelessness or houselessness as george carlin...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brilliant overacting by lesley ann warren best...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is easily the most underrated film inn th...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>this is not the typical mel brooks film it was...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text rating\n",
       "0  bromwell high is a cartoon comedy it ran at th...      9\n",
       "1  homelessness or houselessness as george carlin...      8\n",
       "2  brilliant overacting by lesley ann warren best...     10\n",
       "3  this is easily the most underrated film inn th...      7\n",
       "4  this is not the typical mel brooks film it was...      8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. pure Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider only rating 1 and 10\n",
    "bayes_df_train = train_df[(train_df.rating == '1') | (train_df.rating == '10')]\n",
    "bayes_df_test = test_df[(test_df.rating == '1') | (test_df.rating == '10')]\n",
    "GOOD_WORDS = defaultdict(int)\n",
    "BAD_WORDS = defaultdict(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating Bayes dictionaries: 9832it [00:01, 7132.18it/s]\n"
     ]
    }
   ],
   "source": [
    "for index, row in tqdm(bayes_df_train.iterrows(), desc='Creating Bayes dictionaries', position=0):\n",
    "    text, rating = row['text'], row['rating']\n",
    "    \n",
    "    for word in text.split():\n",
    "        if rating == '10':\n",
    "            GOOD_WORDS[word] += 1\n",
    "        else:\n",
    "            BAD_WORDS[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 56972),\n",
       " ('and', 30301),\n",
       " ('a', 26016),\n",
       " ('of', 25791),\n",
       " ('to', 22249),\n",
       " ('is', 19380),\n",
       " ('in', 16257),\n",
       " ('i', 14729),\n",
       " ('it', 14595),\n",
       " ('this', 13341)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent GOOD words\n",
    "list(sorted(GOOD_WORDS.items(), key=lambda x: x[1], reverse=True))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 58427),\n",
       " ('a', 28386),\n",
       " ('and', 26617),\n",
       " ('to', 26292),\n",
       " ('of', 25218),\n",
       " ('is', 18370),\n",
       " ('this', 18239),\n",
       " ('i', 17985),\n",
       " ('it', 15645),\n",
       " ('in', 15538)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent BAD words\n",
    "list(sorted(BAD_WORDS.items(), key=lambda x: x[1], reverse=True))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text, target_dict):\n",
    "    text = regex(text)\n",
    "    \n",
    "    for word in text.split():\n",
    "        if not word in target_dict:\n",
    "            target_dict[word] = 1\n",
    "            \n",
    "    sum_of_all = sum(target_dict.values())\n",
    "    \n",
    "    ppd = 0\n",
    "    for word in text.split():\n",
    "        ppd += np.log2(float(target_dict[word]) / sum_of_all)\n",
    "        \n",
    "    return ppd\n",
    "    \n",
    "    \n",
    "def predict(text):\n",
    "    ppd_good = classify(text, GOOD_WORDS)\n",
    "    ppd_bad = classify(text, BAD_WORDS)\n",
    "\n",
    "    \n",
    "    all_ppd = np.array([ppd_good, ppd_bad])\n",
    "    target = ['10', '1'][np.argmax(all_ppd)]\n",
    "    \n",
    "    return target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Checking train accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking train accuracy: 9832it [00:23, 423.25it/s]\n"
     ]
    }
   ],
   "source": [
    "correct, wrong = 0, 0\n",
    "real_targets, predictions = [], []\n",
    "\n",
    "for index, row in tqdm(bayes_df_train.iterrows(), desc='Checking train accuracy', position=0):\n",
    "    text, rating = row['text'], row['rating']\n",
    "    \n",
    "    pred = predict(text)\n",
    "    real_targets.append(rating)\n",
    "    predictions.append(pred)\n",
    "    if pred == rating:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1\n",
    "        \n",
    "    if pred == '10' and rating == '1':\n",
    "        FP += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 9311, Wrong: 521\n",
      "Accuracy: 94.70097640358016%\n",
      "\n",
      "Confusion matrix:\n",
      "[[4976  397]\n",
      " [ 124 4335]]\n",
      "\n",
      "True negative (rating = 1): 4976\n",
      "True positive (rating = 10): 4335\n",
      "False negative: 397\n",
      "False positive: 124\n"
     ]
    }
   ],
   "source": [
    "print(f'Correct: {correct}, Wrong: {wrong}')\n",
    "print(f'Accuracy: {correct / (wrong + correct) * 100}%')\n",
    "\n",
    "M = metrics.confusion_matrix(predictions, real_targets)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*So we are rather sceptic and most of our mistakes are movies which are good, but we classify them as bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Checking test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking test accuracy: 10021it [00:23, 424.32it/s]\n"
     ]
    }
   ],
   "source": [
    "correct, wrong = 0, 0\n",
    "real_targets, predictions = [], []\n",
    "\n",
    "for index, row in tqdm(bayes_df_test.iterrows(), desc='Checking test accuracy', position=0):\n",
    "    text, rating = row['text'], row['rating']\n",
    "    \n",
    "    pred = predict(text)\n",
    "    real_targets.append(rating)\n",
    "    predictions.append(pred)\n",
    "\n",
    "    if pred == rating:\n",
    "        correct += 1\n",
    "    else:\n",
    "        wrong += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 8877, Wrong: 1144\n",
      "Accuracy: 88.58397365532382%\n",
      "\n",
      "Confusion matrix:\n",
      "[[4690  812]\n",
      " [ 332 4187]]\n",
      "\n",
      "True negative (rating = 1): 4690\n",
      "True positive (rating = 10): 4187\n",
      "False negative: 812\n",
      "False positive: 332\n"
     ]
    }
   ],
   "source": [
    "print(f'Correct: {correct}, Wrong: {wrong}')\n",
    "print(f'Accuracy: {correct / (wrong + correct) * 100}%')\n",
    "\n",
    "M = metrics.confusion_matrix(predictions, real_targets)\n",
    "print('\\nConfusion matrix:')\n",
    "print(M)\n",
    "print(f'\\nTrue negative (rating = 1): {M[0][0]}')\n",
    "print(f'True positive (rating = 10): {M[1][1]}')\n",
    "print(f'False negative: {M[0][1]}')\n",
    "print(f'False positive: {M[1][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Again we are sceptic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. stemmed Naive Bayes without stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
